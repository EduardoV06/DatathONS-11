{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"DatathONS-11/CARGA_ENERGIA_2024.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_subsistema</th>\n",
       "      <th>nom_subsistema</th>\n",
       "      <th>din_instante</th>\n",
       "      <th>val_cargaenergiamwmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>Norte</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>6532.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NE</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>11658.740083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>Sul</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>10472.403292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SE</td>\n",
       "      <td>Sudeste/Centro-Oeste</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>35089.386708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>Norte</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>7154.334333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>SE</td>\n",
       "      <td>Sudeste/Centro-Oeste</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>40639.167375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>N</td>\n",
       "      <td>Norte</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>7579.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>NE</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>13092.667583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>S</td>\n",
       "      <td>Sul</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>11997.240667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>SE</td>\n",
       "      <td>Sudeste/Centro-Oeste</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>38959.762458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_subsistema        nom_subsistema din_instante  val_cargaenergiamwmed\n",
       "0                N                 Norte   2024-01-01            6532.986042\n",
       "1               NE              Nordeste   2024-01-01           11658.740083\n",
       "2                S                   Sul   2024-01-01           10472.403292\n",
       "3               SE  Sudeste/Centro-Oeste   2024-01-01           35089.386708\n",
       "4                N                 Norte   2024-01-02            7154.334333\n",
       "...            ...                   ...          ...                    ...\n",
       "1459            SE  Sudeste/Centro-Oeste   2024-12-30           40639.167375\n",
       "1460             N                 Norte   2024-12-31            7579.586500\n",
       "1461            NE              Nordeste   2024-12-31           13092.667583\n",
       "1462             S                   Sul   2024-12-31           11997.240667\n",
       "1463            SE  Sudeste/Centro-Oeste   2024-12-31           38959.762458\n",
       "\n",
       "[1464 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def resample_and_merge(df_e, df_c, time_col='timestamp', freq='H'):\n",
    "    # time_col como datetime\n",
    "    df_e = df_e.copy()\n",
    "    df_c = df_c.copy()\n",
    "    df_e[time_col] = pd.to_datetime(df_e[time_col])\n",
    "    df_c[time_col] = pd.to_datetime(df_c[time_col])\n",
    "    df_e = df_e.set_index(time_col).resample(freq).mean()\n",
    "    df_c = df_c.set_index(time_col).resample(freq).mean()\n",
    "    df = pd.concat([df_e, df_c], axis=1)\n",
    "    return df\n",
    "\n",
    "def rolling_features(df, cols, windows=[1,3,24]):\n",
    "    for c in cols:\n",
    "        for w in windows:\n",
    "            df[f'{c}_rmean_{w}'] = df[c].rolling(w, min_periods=1).mean()\n",
    "            df[f'{c}_rstd_{w}'] = df[c].rolling(w, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "def test_stationarity(series, alpha=0.05):\n",
    "    # ADF test: True se estacionária\n",
    "    series = series.dropna()\n",
    "    if len(series) < 20:\n",
    "        return False\n",
    "    stat, p, *_ = adfuller(series, maxlag=12, autolag='AIC')\n",
    "    return p < alpha\n",
    "\n",
    "def compute_pair_metrics(df, x_col, y_col, max_lag=24, corr_method='pearson'):\n",
    "    results = []\n",
    "    xs = df[x_col]; ys = df[y_col]\n",
    "    # raw correlation\n",
    "    for lag in range(0, max_lag+1):\n",
    "        if lag == 0:\n",
    "            xs_l = xs\n",
    "        else:\n",
    "            xs_l = xs.shift(lag)\n",
    "        pair = pd.concat([xs_l, ys], axis=1).dropna()\n",
    "        if len(pair) < 30:\n",
    "            continue\n",
    "        try:\n",
    "            if corr_method == 'pearson':\n",
    "                r, p = pearsonr(pair.iloc[:,0], pair.iloc[:,1])\n",
    "            else:\n",
    "                r, p = spearmanr(pair.iloc[:,0], pair.iloc[:,1])\n",
    "        except Exception:\n",
    "            r, p = np.nan, np.nan\n",
    "        # mutual info (regression)\n",
    "        try:\n",
    "            mi = mutual_info_regression(pair.iloc[:,0].values.reshape(-1,1), pair.iloc[:,1].values, random_state=0)[0]\n",
    "        except Exception:\n",
    "            mi = np.nan\n",
    "        results.append({'x': x_col, 'y': y_col, 'lag': lag, 'corr': r, 'pvalue': p, 'mi': mi, 'n': len(pair)})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def granger_pairs(df, x_col, y_col, maxlag=6):\n",
    "    # Granger: does x -> y ?\n",
    "    data = df[[y_col, x_col]].dropna()\n",
    "    if len(data) < maxlag*5:\n",
    "        return None\n",
    "    try:\n",
    "        res = grangercausalitytests(data, maxlag=maxlag, verbose=False)\n",
    "        # pick best lag by p-value of F-test\n",
    "        pvals = {lag: res[lag][0]['ssr_ftest'][1] for lag in res}\n",
    "        best_lag = min(pvals, key=pvals.get)\n",
    "        return {'x': x_col, 'y': y_col, 'best_lag': best_lag, 'pvalue': pvals[best_lag]}\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_insights(df, energy_cols, climate_cols, freq='H',\n",
    "                     max_lag=24, corr_method='pearson', top_k=20):\n",
    "    # assume df already merged & preprocessed\n",
    "    records = []\n",
    "    for xe in energy_cols:\n",
    "        for yc in climate_cols:\n",
    "            pair_df = compute_pair_metrics(df, xe, yc, max_lag=max_lag, corr_method=corr_method)\n",
    "            if pair_df is None or pair_df.empty:\n",
    "                continue\n",
    "            # pick top absolute correlation across lags\n",
    "            pair_df['corr_abs'] = pair_df['corr'].abs()\n",
    "            best = pair_df.sort_values('corr_abs', ascending=False).iloc[0]\n",
    "            # granger\n",
    "            g = granger_pairs(df, xe, yc, maxlag=min(6, max_lag))\n",
    "            # stability: fraction of windows with same sign corr\n",
    "            signs = []\n",
    "            window_size = 24*7  # 1 week\n",
    "            for start in range(0, len(df)-window_size, window_size):\n",
    "                seg = df[xe].iloc[start:start+window_size].corr(df[yc].iloc[start:start+window_size])\n",
    "                signs.append(np.sign(seg) if not np.isnan(seg) else 0)\n",
    "            stability = np.mean([1 if s == np.sign(best['corr']) else 0 for s in signs]) if signs else 0\n",
    "            records.append({\n",
    "                'x': xe, 'y': yc, 'lag': int(best['lag']), 'corr': float(best['corr']),\n",
    "                'pvalue': float(best['pvalue']) if not np.isnan(best['pvalue']) else np.nan,\n",
    "                'mi': float(best['mi']) if not np.isnan(best['mi']) else np.nan,\n",
    "                'n': int(best['n']), 'stability': float(stability),\n",
    "                'granger_p': g['pvalue'] if g else np.nan, 'granger_lag': g['best_lag'] if g else np.nan\n",
    "            })\n",
    "    dfr = pd.DataFrame(records)\n",
    "    # scoring (normalize components)\n",
    "    df_nonan = dfr.fillna(0)\n",
    "    df_nonan['score'] = (df_nonan['corr'].abs() * 0.5 +\n",
    "                         (1 - df_nonan['pvalue'].clip(0,1)) * 0.2 +\n",
    "                         (df_nonan['mi'] / (df_nonan['mi'].max() + 1e-9)) * 0.2 +\n",
    "                         df_nonan['stability'] * 0.1)\n",
    "    return df_nonan.sort_values('score', ascending=False).head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284f1fe0595e4ab1bbed188e0ea9e704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Clima pronto: ['precipitacao_total__horário_mm', 'pressao_atmosferica_ao_nivel_da_estacao__horaria_mb', 'pressao_atmosferica_maxna_hora_ant_aut_mb', 'pressao_atmosferica_min_na_hora_ant_aut_mb', 'radiacao_global_kj/m²', 'temperatura_do_ar_-_bulbo_seco__horaria_°c', 'temperatura_do_ponto_de_orvalho_°c', 'temperatura_máxima_na_hora_ant_aut_°c', 'temperatura_mínima_na_hora_ant_aut_°c', 'temperatura_orvalho_max_na_hora_ant_aut_°c', 'temperatura_orvalho_min_na_hora_ant_aut_°c', 'umidade_rel_max_na_hora_ant_aut_%', 'umidade_rel_min_na_hora_ant_aut_%', 'umidade_relativa_do_ar__horaria_%', 'vento__direcao_horaria_gr_°_gr', 'vento__rajada_maxima_m/s', 'vento__velocidade_horaria_m/s', 'unnamed:_19']\n",
      "4 - Merge feito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        x                                                  y  \\\n",
      "8   val_cargaenergiamwmed              temperatura_mínima_na_hora_ant_aut_°c   \n",
      "5   val_cargaenergiamwmed         temperatura_do_ar_-_bulbo_seco__horaria_°c   \n",
      "7   val_cargaenergiamwmed              temperatura_máxima_na_hora_ant_aut_°c   \n",
      "10  val_cargaenergiamwmed         temperatura_orvalho_min_na_hora_ant_aut_°c   \n",
      "6   val_cargaenergiamwmed                 temperatura_do_ponto_de_orvalho_°c   \n",
      "9   val_cargaenergiamwmed         temperatura_orvalho_max_na_hora_ant_aut_°c   \n",
      "3   val_cargaenergiamwmed         pressao_atmosferica_min_na_hora_ant_aut_mb   \n",
      "1   val_cargaenergiamwmed  pressao_atmosferica_ao_nivel_da_estacao__horar...   \n",
      "2   val_cargaenergiamwmed          pressao_atmosferica_maxna_hora_ant_aut_mb   \n",
      "12  val_cargaenergiamwmed                  umidade_rel_min_na_hora_ant_aut_%   \n",
      "\n",
      "    lag      corr        pvalue        mi    n  stability     granger_p  \\\n",
      "8     0  0.585113  5.317947e-35  0.390433  366        1.0  6.117907e-04   \n",
      "5     0  0.588077  2.016209e-35  0.376713  366        1.0  4.576874e-04   \n",
      "7     0  0.591866  5.750955e-36  0.364545  366        1.0  4.892572e-04   \n",
      "10   23  0.461236  1.799188e-19  0.238615  343        1.0  3.780227e-01   \n",
      "6    22  0.460002  2.045344e-19  0.205718  344        1.0  4.284575e-01   \n",
      "9    22  0.459478  2.273167e-19  0.192884  344        1.0  4.414535e-01   \n",
      "3     0 -0.418575  5.873637e-17  0.158101  366        1.0  2.527992e-02   \n",
      "1     0 -0.417145  7.670029e-17  0.141778  366        1.0  3.276021e-02   \n",
      "2     0 -0.412797  1.713077e-16  0.133343  366        1.0  3.153134e-02   \n",
      "12   24  0.407611  4.024339e-15  0.214197  342        0.5  5.763551e-07   \n",
      "\n",
      "    granger_lag     score  \n",
      "8             1  0.792557  \n",
      "5             1  0.787010  \n",
      "7             1  0.782672  \n",
      "10            1  0.652848  \n",
      "6             4  0.635380  \n",
      "9             4  0.628544  \n",
      "3             3  0.590275  \n",
      "1             3  0.581198  \n",
      "2             3  0.574703  \n",
      "12            1  0.563528  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/ons/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "con = duckdb.connect(database=':memory:')\n",
    "print(\"1\")\n",
    "\n",
    "df_energy = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('DatathONS-11/CARGA_ENERGIA_2024.parquet')\n",
    "    WHERE nom_subsistema='Sudeste/Centro-Oeste'\n",
    "\"\"\").df()\n",
    "\n",
    "df_energy['din_instante'] = pd.to_datetime(df_energy['din_instante'])\n",
    "df_energy.set_index('din_instante', inplace=True)\n",
    "df_energy = df_energy[['val_cargaenergiamwmed']] \n",
    "print(\"2\")\n",
    "\n",
    "con.execute(\"INSTALL sqlite; LOAD sqlite;\")  # só na primeira vez\n",
    "df_clima = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM sqlite_scan('climate.db', 'climate')\n",
    "\"\"\").df()\n",
    "print(\"3\")\n",
    "\n",
    "df_clima['datetime'] = pd.to_datetime(df_clima['data'] + ' ' + df_clima['hora_utc'], errors='coerce')\n",
    "df_clima = df_clima.set_index('datetime')\n",
    "\n",
    "cols_to_keep = [c for c in df_clima.columns if df_clima[c].dtype in ['float64', 'int64']]\n",
    "df_clima = df_clima[cols_to_keep].rename(\n",
    "    columns=lambda x: x.lower()\n",
    "                   .replace(' ','_')\n",
    "                   .replace('(', '')\n",
    "                   .replace(')','')\n",
    "                   .replace(',', '_')\n",
    "                   .replace('.', '')\n",
    ")\n",
    "print(\"Clima pronto:\", df_clima.columns.tolist())\n",
    "\n",
    "\n",
    "df_clima_daily = df_clima.resample('D').mean()\n",
    "df_energy.index = df_energy.index.tz_localize('UTC')\n",
    "df_clima_daily.index = df_clima_daily.index.tz_convert('UTC')\n",
    "df_merged = df_energy.join(df_clima_daily, how='inner')\n",
    "\n",
    "\n",
    "print(\"4 - Merge feito\")\n",
    "\n",
    "\n",
    "energy_cols = ['val_cargaenergiamwmed']\n",
    "climate_cols = list(df_clima_daily.columns)\n",
    "\n",
    "insights = extract_insights(df_merged, energy_cols, climate_cols, max_lag=24, top_k=10)\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "top_pairs = insights[['x','y','lag']]\n",
    "\n",
    "heatmap_data = pd.DataFrame(index=range(0,25), columns=top_pairs['y'].values)\n",
    "\n",
    "for _, row in top_pairs.iterrows():\n",
    "    x = row['x']\n",
    "    y = row['y']\n",
    "    lag = row['lag']\n",
    "    corrs = []\n",
    "    for l in range(0,25):\n",
    "        shifted_x = df_merged[x].shift(l)\n",
    "        corr = shifted_x.corr(df_merged[y])\n",
    "        heatmap_data.loc[l, y] = corr\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(heatmap_data.astype(float), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Heatmap de correlações por lag (0-24 dias)\")\n",
    "plt.xlabel(\"Variáveis Climáticas\")\n",
    "plt.ylabel(\"Lag (dias)\")\n",
    "plt.show()\n",
    "\n",
    "for _, row in top_pairs.iterrows():\n",
    "    x = row['x']\n",
    "    y = row['y']\n",
    "    lag = row['lag']\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot(df_merged.index, df_merged[x], label=x)\n",
    "    plt.plot(df_merged.index, df_merged[y].shift(lag), label=f\"{y} (lag={lag})\")\n",
    "    plt.title(f\"Séries Temporais: {x} vs {y} (lag {lag})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "window_size = 7  # em dias\n",
    "for _, row in top_pairs.iterrows():\n",
    "    x = row['x']\n",
    "    y = row['y']\n",
    "    signs = []\n",
    "    n_windows = len(df_merged) // window_size\n",
    "    for start in range(0, len(df_merged)-window_size, window_size):\n",
    "        seg = df_merged[x].iloc[start:start+window_size].corr(df_merged[y].iloc[start:start+window_size])\n",
    "        signs.append(np.sign(seg) if not np.isnan(seg) else 0)\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.bar(range(len(signs)), signs)\n",
    "    plt.title(f\"Estabilidade da correlação: {x} vs {y}\")\n",
    "    plt.ylabel(\"Sinal da correlação\")\n",
    "    plt.xlabel(\"Janelas semanais\")\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(data=insights, x='score', y='y', orient='h')\n",
    "plt.title(\"Importância das variáveis climáticas (Score agregado)\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Variável Climática\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.stats import pearsonr\n",
    "import plotly.subplots as sp\n",
    "\n",
    "def detect_var_type(series):\n",
    "    n_unique = series.nunique()\n",
    "    if pd.api.types.is_numeric_dtype(series) and n_unique > 20:\n",
    "        return 'continuous'\n",
    "    else:\n",
    "        return 'categorical'\n",
    "\n",
    "def normalize_series(df, cols):\n",
    "    scaler = MinMaxScaler()\n",
    "    df_norm = df.copy()\n",
    "    df_norm[cols] = scaler.fit_transform(df[cols])\n",
    "    return df_norm\n",
    "\n",
    "def compute_stability(df, x_col, y_col, window_size=24*7):\n",
    "    signs = []\n",
    "    for start in range(0, len(df)-window_size, window_size):\n",
    "        seg = df[x_col].iloc[start:start+window_size].corr(df[y_col].iloc[start:start+window_size])\n",
    "        signs.append(np.sign(seg) if not np.isnan(seg) else 0)\n",
    "    return signs\n",
    "\n",
    "\n",
    "def plot_insight_panel_interactive(df, x_col, y_col, lag=0, metrics=None):\n",
    "    y_shifted = df[y_col].shift(lag) if lag > 0 else df[y_col]\n",
    "    df_plot = pd.DataFrame({x_col: df[x_col], y_col: y_shifted}).dropna()\n",
    "\n",
    "    var_type = detect_var_type(y_shifted)\n",
    "    if var_type == 'continuous':\n",
    "        df_plot = normalize_series(df_plot, [x_col, y_col])\n",
    "\n",
    "    stability_series = compute_stability(df_plot, x_col, y_col)\n",
    "\n",
    "\n",
    "    fig = sp.make_subplots(\n",
    "        rows=3, cols=3,\n",
    "        subplot_titles=[\n",
    "            'Séries Temporais Normalizadas',\n",
    "            'Distribuição / Contagem',\n",
    "            'Scatter + Regressão',\n",
    "            'Heatmap Correlação por Lag',\n",
    "            'Boxplot Mensal',\n",
    "            'Métricas de Insight',\n",
    "            'Estabilidade por janelas semanais',\n",
    "            'Scatter múltiplos (Top 3)',\n",
    "            ''\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot[x_col], name=x_col), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot[y_col], name=y_col), row=1, col=1)\n",
    "\n",
    "    if var_type == 'continuous':\n",
    "        fig.add_trace(go.Histogram(x=df_plot[y_col], name=y_col), row=1, col=2)\n",
    "    else:\n",
    "        vc = df_plot[y_col].value_counts()\n",
    "        fig.add_trace(go.Bar(x=vc.index, y=vc.values, name=y_col), row=1, col=2)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df_plot[y_col], y=df_plot[x_col], mode='markers', name='scatter'), row=1, col=3)\n",
    "\n",
    "    lags = min(24, len(df_plot)//2)\n",
    "    corr_values = [pearsonr(df_plot[x_col], df_plot[y_col].shift(l))[0] for l in range(lags)]\n",
    "    fig.add_trace(go.Heatmap(z=np.array(corr_values).reshape(-1,1), colorscale='RdBu', showscale=True), row=2, col=1)\n",
    "\n",
    "    df_box = df_plot.copy()\n",
    "    df_box['month'] = df_box.index.month\n",
    "    for m in df_box['month'].unique():\n",
    "        fig.add_trace(go.Box(y=df_box[df_box['month']==m][y_col], name=str(m)), row=2, col=2)\n",
    "\n",
    "    if metrics:\n",
    "        fig.add_trace(go.Bar(x=list(metrics.keys()), y=list(metrics.values())), row=2, col=3)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=list(range(len(stability_series))), y=stability_series), row=3, col=1)\n",
    "\n",
    "    top3_cols = [y_col] + df_plot.columns.drop(x_col).tolist()[:2]\n",
    "    col_idx = 0\n",
    "    for col in top3_cols:\n",
    "        fig.add_trace(go.Scatter(x=df_plot[col], y=df_plot[x_col], mode='markers', name=f'{x_col} vs {col}'), row=3, col=2+col_idx%2)\n",
    "        col_idx += 1\n",
    "\n",
    "    fig.update_layout(height=1200, width=1600, title_text=f'Painel Interativo: {x_col} vs {y_col} (lag={lag})')\n",
    "    fig.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Aplicar para top 10 insights\n",
    "# -------------------------------\n",
    "top10_insights = insights.head(10)\n",
    "\n",
    "for idx, row in top10_insights.iterrows():\n",
    "    metrics = {\n",
    "        'corr': row['corr'],\n",
    "        'mi': row['mi'],\n",
    "        'granger_p': row['granger_p'],\n",
    "        'stability': row['stability']\n",
    "    }\n",
    "    plot_insight_panel_interactive(df_merged, row['x'], row['y'], lag=int(row['lag']), metrics=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
